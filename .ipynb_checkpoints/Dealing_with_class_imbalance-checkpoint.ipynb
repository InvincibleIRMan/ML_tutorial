{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1784729b",
   "metadata": {},
   "source": [
    "# Dealing with class imbalance\n",
    "\n",
    "Class imbalance is a major problem in any __\"real-world\"__ classification task.\n",
    "\n",
    "Assume you are dealing with classifying violence vs non-violence scenarios from video sequences streaming from a security camera, and the task of this camera is to identify __violence__ vs __non-Violence__ scenarios. We all know that \n",
    "$99.9\\%$ of the time, security camera record the \"normal\" (non-violence) scenarios while detecting \"violence\" behavior can be considered as a rare event.\n",
    "\n",
    "Similarly in the medical diagnosis use case for a rare disease, in this case we generally dealing with highly \"imbalance\" samples.\n",
    "\n",
    "In this tutorial you will learn about:\n",
    "    \n",
    "    1. Effect of class imbalance on your model training\n",
    "    2. Two major techniques to deal with the class imbalance:\n",
    "        a. Oversampling\n",
    "        b. Penalization\n",
    "        c. Oversampling + Penalization\n",
    "    3. Metrics to effectly monitor your training procedure.\n",
    "\n",
    "In this tutorial similar to the provious one we will work with the Malaria Dataset. However, to simulate the class imbalance we extract a subset from the dataset such that the ratio between the positive class \"infected\" and negative class \"uninfected\" is 100/1000 for training and 10/90 for the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d12551c",
   "metadata": {},
   "source": [
    "# Steps to establish a machine learning pipeline for this tutorial\n",
    "1. Dataloading and shaping an imbalance dataset\n",
    "2. Torch ready data prepration\n",
    "3. Model definition\n",
    "4. Optimizer and loss definition\n",
    "5. Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5982d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from monai.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged, \n",
    "    AddChanneld, \n",
    "    RandFlipd, \n",
    "    RandRotate90d, \n",
    "    Resized, \n",
    "    EnsureChannelFirstd,\n",
    "    RandGaussianNoised,\n",
    "    ToTensord\n",
    "    )\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c6887",
   "metadata": {},
   "source": [
    "## Dataloading and creating an imbalance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e51b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of infected samples is 13780 and number of unifected is 13780\n",
      "number of train samples is 1000 and number of test is 100\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/Users/sadeghmh/Desktop/Projects/data/cell_images/'\n",
    "infected_name = 'Parasitized'\n",
    "uninfected_name = 'Uninfected'\n",
    "df_infected = pd.DataFrame({'image_name':os.listdir(os.path.join(root_dir,infected_name)), \n",
    "                          'folder_name': [infected_name for _ in range(len(os.listdir(os.path.join(root_dir,infected_name))))],\n",
    "                         'label': [1 for _ in range(len(os.listdir(os.path.join(root_dir,infected_name))))]})\n",
    "\n",
    "df_uninfected = pd.DataFrame({'image_name':os.listdir(os.path.join(root_dir,uninfected_name)), \n",
    "                            'folder_name': [uninfected_name for _ in range(len(os.listdir(os.path.join(root_dir,uninfected_name))))],\n",
    "                             'label': [0 for _ in range(len(os.listdir(os.path.join(root_dir,uninfected_name))))]})\n",
    "\n",
    "# select the subset of the data\n",
    "df_infected_sample = df_infected.sample(n=100, random_state=42).reset_index()\n",
    "df_uninfected_sample = df_uninfected.sample(n= 1000, random_state=42).reset_index()\n",
    "\n",
    "# Create the train/test split\n",
    "# train\n",
    "df_infected_train = df_infected_sample.loc[0:89]\n",
    "df_uninfected_train = df_uninfected_sample.loc[0:909]\n",
    "df_list = [df_infected_train, df_uninfected_train]\n",
    "df_train = pd.concat(df_list).reset_index()\n",
    "# test\n",
    "df_infected_test = df_infected_sample.loc[90:]\n",
    "df_uninfected_test = df_uninfected_sample.loc[910:]\n",
    "\n",
    "df_list = [df_infected_test, df_uninfected_test]\n",
    "df_val = pd.concat(df_list).reset_index()\n",
    "\n",
    "\n",
    "print('number of infected samples is {} and number of unifected is {}'.format(len(df_infected), len(df_uninfected)))\n",
    "print('number of train samples is {} and number of test is {}'.format(len(df_train), len(df_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7431005",
   "metadata": {},
   "source": [
    "### Distribution of training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51e54f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 910\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_infected = len(df_train[df_train['label'] == 1])\n",
    "num_uninfected = len(df_train[df_train['label'] == 0])\n",
    "df_num = pd.DataFrame({'cell status':['infected','unifected'], 'distribution':[num_infected, num_uninfected]}, columns=['cell status', 'distribution'])\n",
    "print(num_infected, num_uninfected)\n",
    "ax = sns.barplot(x=\"cell status\", y=\"distribution\", data=df_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b52be",
   "metadata": {},
   "source": [
    "### Weight computation, for oversampling and also penalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5345d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train['label'].to_numpy()\n",
    "class_sample_count = np.array(\n",
    "    [len(np.where(target == t)[0]) for t in np.unique(target)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in target])\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weigth = samples_weight.double()\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6ecc90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([910,  90])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "528426e6",
   "metadata": {},
   "source": [
    "## Helper function to shape the training and validation set in an acceptable Monai format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5eed19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2dict(df):\n",
    "    data_dict = {}\n",
    "    list_of_dict = []\n",
    "    for i in range(0,len(df)):\n",
    "        #data_dict['image'] = os.path.join(root_dir,df.iloc[i,1],df.iloc[i,0])\n",
    "        data_dict['image'] = os.path.join(root_dir,df['folder_name'][i],df['image_name'][i])\n",
    "        data_dict['label'] = df['label'][i]\n",
    "        list_of_dict.append(data_dict.copy())\n",
    "    return list_of_dict\n",
    "data_train = list2dict(df_train)\n",
    "data_val = list2dict(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12402266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7992055",
   "metadata": {},
   "source": [
    "### Torch ready transformation, Monai plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be44effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        Resized(keys=[\"image\"],spatial_size=(224,224)),\n",
    "        RandFlipd(keys=[\"image\"], prob=0.5),\n",
    "        RandRotate90d(keys=[\"image\"], prob=0.5),\n",
    "        RandGaussianNoised(keys=[\"image\"], prob=0.2),\n",
    "        ToTensord(keys=[\"image\"])\n",
    "])\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        Resized(keys=[\"image\"],spatial_size=(224,224)),\n",
    "        ToTensord(keys=[\"image\"])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df54c70",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6e25281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampling = True\n",
    "\n",
    "ds_tr = Dataset(data=data_train,transform= train_transforms) # create dataset\n",
    "if oversampling == True:\n",
    "    ds_tr_loader = DataLoader(ds_tr, batch_size=100, sampler =sampler)\n",
    "else:\n",
    "    ds_tr_loader = DataLoader(ds_tr, batch_size=100, shuffle = True)\n",
    "\n",
    "ds_val = Dataset(data=data_val,transform= val_transforms) # create dataset\n",
    "ds_val_loader = DataLoader(ds_val, batch_size=100)\n",
    "\n",
    "len(ds_tr), len(ds_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bf4262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch index 0, 0/1: 52/48\n",
      "batch index 1, 0/1: 58/42\n",
      "batch index 2, 0/1: 45/55\n",
      "batch index 3, 0/1: 43/57\n",
      "batch index 4, 0/1: 41/59\n",
      "batch index 5, 0/1: 48/52\n",
      "batch index 6, 0/1: 48/52\n",
      "batch index 7, 0/1: 52/48\n",
      "batch index 8, 0/1: 46/54\n",
      "batch index 9, 0/1: 49/51\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(ds_tr_loader):\n",
    "    target = batch['label']\n",
    "    print (\"batch index {}, 0/1: {}/{}\".format(\n",
    "        i,\n",
    "        len(np.where(target.numpy() == 0)[0]),\n",
    "        len(np.where(target.numpy() == 1)[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b55b7",
   "metadata": {},
   "source": [
    "# Define model, we use Resnet 50 for this purpose!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5026e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/sadeghmh/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = torch.hub.load('pytorch/vision:v0.9.0', 'resnet50', pretrained=True)\n",
    "net.fc = nn.Linear(in_features=2048, out_features=2) # only last year needed to be replace\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f01d500",
   "metadata": {},
   "source": [
    "## Define Optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4219a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "penalization = True\n",
    "if penalization == True:\n",
    "    penalization_weight = np.min(class_sample_count)/class_sample_count  #  Weight of class C is the size of smallest class divided by the size of class C, Alternatively you can divide the size of the largest class and divide them in the class C\n",
    "    penalization_weight = torch.from_numpy(penalization_weight).float()\n",
    "    criterion = nn.CrossEntropyLoss(penalization_weight)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb0b4251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([910,  90]), array([0.0989011, 1.       ]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_sample_count,  np.min(class_sample_count)/class_sample_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e138d2",
   "metadata": {},
   "source": [
    "# training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d565812",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "net.train()\n",
    "\n",
    "tracker = dict()\n",
    "accuracy_tr = list()\n",
    "loss_tr = list()\n",
    "accuracy_val = list()\n",
    "loss_val = list()\n",
    "auc_tr = list()\n",
    "auc_val = list()\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    pred_iter = list()\n",
    "    target_iter = list()\n",
    "    accuracy_tr_iter = list()\n",
    "    running_loss_tr = 0\n",
    "    total_data_tr = 0\n",
    "    running_loss_te = 0\n",
    "    total_data_te = 0\n",
    "    for i, batch in enumerate(ds_tr_loader):\n",
    "        data = batch['image'].to(device)\n",
    "        target = batch['label'].to(device)\n",
    "        outputs = net(data)\n",
    "        _,preds = torch.max(outputs,1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_iter.extend(preds.cpu().numpy())\n",
    "        target_iter.extend(target.cpu().numpy())\n",
    "        running_loss_tr += loss.item() * data.size(0)\n",
    "        total_data_tr += data.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss_tr / total_data_tr\n",
    "    loss_tr.append(epoch_loss)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(target_iter, pred_iter)\n",
    "    AUC = auc(fpr, tpr)\n",
    "    ACC = accuracy_score(target_iter,pred_iter)\n",
    "    auc_tr.append(AUC)\n",
    "    accuracy_tr.append(ACC)\n",
    "    \n",
    "    print('training Phase: epoch: {} Loss: {:.4f} Acc: {:.4f} AUC: {:.4f}'.format(\n",
    "                epoch , epoch_loss, ACC, AUC))\n",
    "    net.eval()\n",
    "    for i, batch in enumerate(ds_val_loader):\n",
    "        data = batch['image'].to(device)\n",
    "        target = batch['label'].to(device)\n",
    "        outputs = net(data)\n",
    "        _,preds = torch.max(outputs,1)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        running_loss_te += loss.item() * data.size(0)\n",
    "        total_data_te += data.size(0)\n",
    "    epoch_loss = running_loss_te / total_data_te\n",
    "    loss_val.append(epoch_loss)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(target.cpu().numpy(), preds.cpu().numpy())\n",
    "    AUC = auc(fpr, tpr)\n",
    "    Acc = accuracy_score(target,preds)\n",
    "    auc_val.append(AUC)\n",
    "    accuracy_val.append(Acc)\n",
    "    print('validation Phase: epoch: {} Loss: {:.2f} Acc: {:.2f} AUC: {:.2f}'.format(\n",
    "                epoch , epoch_loss, ACC, AUC))\n",
    "\n",
    "tracker['loss_tr'] = loss_tr\n",
    "tracker['loss_val'] = loss_val\n",
    "tracker['accuracy_tr'] = accuracy_tr\n",
    "tracker['accuracy_val'] = accuracy_val\n",
    "tracker['auc_tr'] = auc_tr\n",
    "tracker['auc_val'] = auc_val\n",
    "        \n",
    "with open(..., 'rb') as f:\n",
    "    pickle.dump(tracker,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad955d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
